{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "xekHDkLMthk6",
        "outputId": "34e40968-03c2-46f9-f0ab-2217d1d8e6e7"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "# Import datasets, classifiers and performance metrics\r\n",
        "from sklearn import datasets, svm, metrics\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "# The digits dataset\r\n",
        "digits = datasets.load_digits()\r\n",
        "\r\n",
        "#print(\"Digits\\n\", digits)\r\n",
        "\r\n",
        "images_and_labels = list(zip(digits.images, digits.target))\r\n",
        "\r\n",
        "# To see some specific number of the images and the respective target.(in this case only 2 rows and 3 columns i.e. 6items)\r\n",
        "#for index, (image, label) in enumerate(images_and_labels[:6]):\r\n",
        "#    plt.subplot(2, 3, index + 1)\r\n",
        "#    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\r\n",
        "#    plt.title('Target: %i' % label)\r\n",
        "\r\n",
        "# To apply a classifier on this data, we need to flatten the image, to\r\n",
        "# turn the data in a (samples, feature) matrix:\r\n",
        "n_samples = len(digits.images)\r\n",
        "data = digits.images.reshape((n_samples, -1))\r\n",
        "#print(\"Data\\n\",data)\r\n",
        "\r\n",
        "# Create a classifier: a support vector classifier\r\n",
        "classifier = svm.SVC(gamma=0.001)\r\n",
        "\r\n",
        "# We learn the digits on the first half of the digits\r\n",
        "trainTestSplit = int(n_samples*0.75)\r\n",
        "classifier.fit(data[:trainTestSplit], digits.target[:trainTestSplit])\r\n",
        "\r\n",
        "# Now predict the value of the digit on the second half:\r\n",
        "expected = digits.target[trainTestSplit:]\r\n",
        "predicted = classifier.predict(data[trainTestSplit:])\r\n",
        "\r\n",
        "#print(\"Classification report for classifier %s:\\n%s\\n\"\r\n",
        "#% (classifier, metrics.classification_report(expected, predicted)))\r\n",
        "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\r\n",
        "print(accuracy_score(expected, predicted))\r\n",
        "\r\n",
        "\r\n",
        "# let's test on the last few images\r\n",
        "plt.imshow(digits.images[-10], cmap=plt.cm.gray_r, interpolation='nearest')\r\n",
        "print(\"Prediction for test image: \", classifier.predict(data[-10].reshape(1,-1)))\r\n",
        "\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[42  0  0  0  1  0  0  0  0  0]\n",
            " [ 0 46  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 43  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 40  0  2  0  1  4  0]\n",
            " [ 0  0  0  0 45  0  0  0  1  2]\n",
            " [ 0  0  0  0  0 44  1  0  0  0]\n",
            " [ 0  0  0  0  0  0 47  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 45  0  0]\n",
            " [ 0  1  0  0  0  0  0  0 40  0]\n",
            " [ 0  0  0  1  0  1  0  0  0 43]]\n",
            "0.9666666666666667\n",
            "Prediction for test image:  [5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}